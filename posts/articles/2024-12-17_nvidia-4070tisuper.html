<!DOCTYPE html><html><head>
      <title>2024-12-17_nvidia-4070tisuper</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:///c:\Users\weibo\.vscode\extensions\shd101wyy.markdown-preview-enhanced-0.8.15\crossnote\dependencies\katex\katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h1 id="nvidia-geforce-rtx-4070-深度学习开发环境--deepseek模型">Nvidia GeForce RTX 4070 深度学习开发环境 + DeepSeek模型 </h1>
<h2 id="4070ti-super参数规格httpswwwnvidiacngeforcegraphics-cards40-seriesrtx-4070-family"><a href="https://www.nvidia.cn/geforce/graphics-cards/40-series/rtx-4070-family/">4070Ti SUPER参数规格</a> </h2>
<p><img src="images/GeForce%20RTX%204070.jpg" alt="alt text"></p>
<ul>
<li>GPU 架构：基于 NVIDIA Ada Lovelace 架构，相比上一代架构，在性能和能效方面有显著提升。它采用了全新的 SM（流式多处理器）设计、第二代 RT Core（光线追踪核心）和第三代 Tensor Core（张量核心），能够为游戏和专业应用程序提供强大的计算能力。</li>
<li>CUDA 核心：拥有 8448 个 CUDA 核心，相比 RTX 4070 Ti 的 7680 个 CUDA 核心有所增加，能够处理更复杂的图形计算任务，提供更流畅的游戏体验和更高的创作效率。</li>
<li>显存规格：配备 16GB GDDR6X 显存，位宽为 256 位，显存带宽达到 672GB/s。大容量的显存和高带宽使得显卡在处理高分辨率、高画质游戏以及专业的图形渲染任务时更加得心应手。</li>
<li>频率：基础频率为 2340MHz，加速频率为 2610MHz，在游戏中，显卡会自动将频率提升至 2717 - 2776MHz，更高的频率有助于提升显卡的性能表现</li>
</ul>
<h2 id="驱动安装">驱动安装 </h2>
<h3 id="查看显卡驱动nvidia-smi">查看显卡驱动（nvidia-smi） </h3>
<p><img src="images/4070tis-driver.jpg" alt="alt text"></p>
<p><a href="https://www.nvidia.cn/drivers/lookup/">查找nvidia最新驱动</a></p>
<h2 id="安装cuda">安装CUDA </h2>
<p><a href="https://developer.nvidia.com/cuda-downloads">下载NVIDIA CUDA Toolkit</a>，选择与操作系统和 GPU 架构相匹配的 CUDA 版本。</p>
<p>安装完成后，windows命令行窗口输入nvcc --version，查看版本号<br>
<a href="https://developer.nvidia.com/cudnn-downloads">下载cuDNN</a>，解压后将下述文件夹拷贝到CUDA安装目录。<br>
<img src="images/cudnn_dir.png" alt="cuDNN文件目录"></p>
<h2 id="安装anaconda">安装Anaconda </h2>
<p><a href="https://www.anaconda.com/download/success">下载Anaconda</a><br>
<a href="https://docs.conda.io/projects/conda/en/latest/user-guide/index.html">Anaconda用户手册</a><br>
一般使用过程：</p>
<ol>
<li>创建虚拟环境 conda create -n <env-name><br>
conda create -n myenvironment python numpy pandas<br>
查看conda info --envs</env-name></li>
<li>激活新创建的环境 conda activate</li>
<li>安装软件包 conda install<br>
conda activate myenvironment<br>
conda install matplotlib</li>
<li>删除环境 conda remove -n myenvironment --all</li>
</ol>
<h2 id="安装python">安装python </h2>
<p>Anaconda自带python，可以通过python --version查看；也可以自行下载安装，如果安装了conda，建议统一管理版本。<br>
<a href="https://www.python.org/downloads/">python官网</a></p>
<h2 id="安装pytorch-cuda">安装pytorch-CUDA </h2>
<p><a href="https://pytorch.org/">pytorch官网</a></p>
<p><img src="images/pytorch-cuda-version.jpg" alt="alt text"></p>
<p>当前CUDA最新版本12.8高于pytorch能支持的CUDA版本12.4，CUDA可能存在向下兼容性问题。</p>
<p><strong>方式一：pip安装</strong><br>
pip install torch torchvision torchaudio --index-url <a href="https://download.pytorch.org/whl/cu124">https://download.pytorch.org/whl/cu124</a></p>
<p><strong>方式二：conda安装</strong><br>
conda install pytorch<mark>2.5.0 torchvision</mark>0.20.0 torchaudio==2.5.0 pytorch-cuda=12.4 -c pytorch -c nvidia</p>
<p>示例：<br>
conda create -n evn_py310 python=3.10 -y<br>
conda activate evn_py310<br>
conda info --env<br>
conda install pytorch<mark>2.5.1 torchvision</mark>0.20.1 torchaudio==2.5.1 pytorch-cuda=12.4 -c pytorch -c nvidia</p>
<p><strong>验证CUDA版本的pytorch</strong><br>
python命令窗口执行：python -c "import torch;print(torch.cuda.is_available())"，打印True说明安装成功。</p>
<pre data-role="codeBlock" data-info="" class="language-text"><code>import torch
 
# 检查CUDA是否可用
if torch.cuda.is_available():
    device = torch.device("cuda")         # 使用CUDA设备
else:
    device = torch.device("cpu")          # 使用CPU设备
 
# 创建一个张量并移动到GPU（如果可用）
x = torch.randn(10, 10).to(device)
y = torch.randn(10, 10).to(device)
 
# 在GPU上执行操作
print(x+y)
</code></pre><h2 id="模型推理hg">模型推理(HG) </h2>
<h3 id="huggingface-transformers">huggingface Transformers </h3>
<p>pip install transformers<br>
pip install 'accelerate&gt;=0.26.0'</p>
<h3 id="qwen25-7b-instruct推理"><strong>Qwen2.5-7B-Instruct推理</strong> </h3>
<pre data-role="codeBlock" data-info="" class="language-text"><code>from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "Qwen/Qwen2.5-7B-Instruct"

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = "写一首冬日蓝天白雪的诗"
messages = [
    {"role": "system", "content": "You are Qwen, created by Alibaba Cloud. You are a helpful assistant."},
    {"role": "user", "content": prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=512
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)

"""
冬日晴空映雪光，古寺静立映寒霜。

银装素裹松柏劲，禅钟悠扬入梦乡。

红墙绿瓦覆轻纱，玉砌雕栏凝冷华。

飞鸟不惊云自淡，一缕香烟绕塔斜。"""

</code></pre><h3 id="deepseek-r1-distill-llama-8b推理"><strong>DeepSeek-R1-Distill-Llama-8B推理</strong> </h3>
<pre data-role="codeBlock" data-info="" class="language-text"><code>from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = "写一首冬日蓝天白雪的诗"
messages = [
    {"role": "system", "content": "You are Qwen, created by Alibaba Cloud. You are a helpful assistant."},
    {"role": "user", "content": prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=2048
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)

"""
好的，用户希望我写一首关于冬日蓝天白雪的诗。首先，我需要理解冬日的景象，蓝天和白雪是主要元素。蓝天可能暗示着晴朗的天气，而白雪则增添了寒冷和宁静的感觉。

接下来，考虑诗的结构。可能选择五言绝句或者七言律诗，这样更符合传统诗歌的韵律。五言绝句比较简洁，适合表达清新自然的意境。

然后，思考每一句的内容。第一句可以描绘天空的蓝色，比如“天色清澈如蓝天”，第二句描述雪景，比如“银装素裹映寒川”。第三句可以加入一些动态的元素，比如“鸟儿飞过”，增加画面感。最后一句表达冬日的宁静与美好，比如“人间冬日好时节”。

赏析部分需要解释诗中的意象和情感，说明如何通过这些意象传达出冬日的宁静与美丽，以及对生活的珍惜。

最后，检查诗句的押韵和节奏，确保整体流畅自然。这样，整首诗就完成了。
&lt;/think&gt;

《冬日蓝天白雪》
天色清澈如蓝天，银装素裹映寒川。
鸟飞过，人间冬日好时节。
莫道寒冷伤心事，且看雪花飘飘烟。

赏析：这首作品描绘了冬日蓝天白雪的宁静与美丽。通过“天色清澈如蓝天，银装素裹映寒川”的描绘，生动展现了冬日的清新与明亮。诗中“鸟飞过，人间冬日好时节”一句，巧妙地融入了动与静，表达了对冬日生活的珍惜与热爱。尾联“莫道寒冷伤心事，且看雪花飘飘烟”，则进一步以豁达的态度对待寒冷，传递出一种积极向上的生活态度。"""
</code></pre>
      </div>
      
      
    
    
    
    
    
    
  
    </body></html>